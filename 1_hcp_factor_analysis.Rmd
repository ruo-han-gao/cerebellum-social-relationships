---
title: "HCD Factor Analysis"
author: "Ruohan Gao"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 3
---

```{r setup, include=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# clear the environment
rm(list = ls())
options(scipen = 999, digits = 3)

workdir = "/data/tu_gaor/scripts"
homedir = "/Users/ruohan/My_Repos/Cerebellum"
cwd_dir = homedir
datadir = file.path(cwd_dir, "dat")

aging_name = "hcpa"
develop_name = "hcpd"

plot_dir = file.path(cwd_dir, "plotting/factor_analysis_plots")

# rmarkdown::run("hcp_factor_analysis.Rmd")
# rmarkdown::render("1_hcp_factor_analysis.Rmd")
```


```{r load packages, message=FALSE}
library(psych)
library(nFactors)
library(tidyr)
library(dplyr)
library(corrplot)
library(RColorBrewer)
library(lavaan)
library(semTools)
library(tibble)
library(ggplot2)
```

----------

## 1  Load data and discriptives

```{r prepare data, warning=FALSE, message=FALSE}
dat_a = read.csv(file.path(datadir, aging_name, "fusion_yeo7_17_socialscore_n590.csv"))
dat_d = read.csv(file.path(datadir, develop_name, "fusion_yeo7_17_socialscore_n443.csv"))

# combine the two datasets
dat <- rbind(dat_a, dat_d)

soc_item22 = dat[, 85:106]
item.labels = colnames(soc_item22)

describe(soc_item22)
```

----------

## 2  Why factor analysis?

We extract 22 items from social health surveys, covering 5 aspects - emotional and instrumental support, friendship, loneliness, perceived rejection, and perceived hostility. Among them, the first 2 assess positive experiences, while later 3 assess negative ones. Therefore, responses to negatively worded items were reverse-coded.

Giving that the items may capture overlapping aspects of social health, factor analyses, as a data-driven approach to uncover how items naturally cluster, were employed to examine the underlying constructs of the included survey items.

----------

## 3  Correlation matrix

```{r correlation matrix, warning=FALSE}
poly_R <- polychoric(soc_item22)$rho

png(file.path(plot_dir, paste0("all", "_items_cor_matrix.png")), 
    width=6, height=6, units="in", res=300)

corrplot(poly_R, method = "square",
         order = "hclust",
         tl.col = "black",
         # addCoef.col = "black",
         tl.cex = 1.2,        # axis label font
         cl.cex = 1.2,        # color bar number size
         family = "Arial",
         col = colorRampPalette(rev(brewer.pal(11, "RdBu")))(200))
dev.off()
```

----------

## 4  Factorability checks

### 4.1  Sampling adequacy

Two diagnostic tests `KMO()` and `cortest.bartlett()` were used to determine whether the data is suitable for factor analysis.

```{r kmo}
KMO(soc_item22)
range(KMO(soc_item22)[2])
```

The `KMO()` function performs the Kaiser-Meyer-Olkin (KMO) Measure of Sampling Adequacy. It answers the question: _“Do the variables share enough common variance to extract underlying factors?”_

  - Using the `KMO()` function, an overall MSA 0.88 was obtained, which falls into the “meritorious” range according to Kaiser’s classification, indicating that the correlations among our variables are sufficiently strong and suitable for factor analysis.
  - The individual KMO values for variables ranged from 0.79 to 0.91, showing that all the items contributed adequately to the overall sampling adequacy and that none should be excluded based on this criterion.

### 4.2  Test of sphericity

```{r cortest}
cortest.check = cortest.bartlett(poly_R, n = nrow(dat))
cat("Chi-square:", cortest.check$chisq, "| df:", cortest.check$df, "| p-value:", cortest.check$p.value, "\n")
```

The `cortest.bartlett()` performs Bartlett's test of sphericity to assess the factorability of the correlation matrix. Simply put - if the correlation matrix is significantly different from an identity matrix, where variables are uncorrelated).

  - It answers the question: _“Are there meaningful correlations among variables?”_
  - A p value of 0 indicated that our variables are correlated enough to justify factor analysis.

----------

## 5  Number of factors to retain

To determine the appropriate number of factors to retain, several criteria were evaluated, including eigenvalues greater than 1, parallel analysis, the minimum average partial (MAP) test, and the Bayesian Information Criterion (BIC). Based on the convergence of results across these methods and considering the factor interpretability, EFA models with factor number of 4 and 5 were test.

### Eingenvalues
From the scree plot, **4 factors** has an eingenvalue of over 1.

```{r vss scree}
ev = eigen(poly_R)$values
plot(ev, type = "b", main = "Scree Plot", xlab = "Factor Number", ylab = "Eigenvalue")
abline(h=1, col="red", lty=2)
```

### Parallel analysis
 suggests that the number of factors to retain = 5.

```{r parallel analysis}
fa.parallel(poly_R, n.obs = nrow(dat), fm = "pa")
```

### MAP and BIC

I tried multiple rotation methods and estimation methods. The results are very similar, with `fm = "pa"` and ``fm = "minres"`showing slightly lower BIC than `fm = "gls"` and `fm = "wls"`. Rotation methods did not affect the results that much. I randomly kept one in this documentation.

```{r MAP, ig.show='hide', fig.keep='none'}
nfactors(x = poly_R, n = 5, rotate = "oblimin", fm = "pa", n.obs = nrow(dat))
```

----------

## 6  Exploratory factor analysis (EFA)

The above methods indicated that the appropriate number of factors to retain should be 4 or 5. Accordingly, Factor models were constructed to test models with either 4 or 5 factors. Both models demonstrated clear and interpretable structures. The 5-factor model aligned well with the theoretical structure of the 5 scales, and the 4-factor model combined items from the Rejection and Loneliness scales into a single factor, suggesting an overlap in their underlying constructs.

To evaluate the internal consistency of the resulting factors, Cronbach’s alpha was computed for each factor structure. All 6 structures (including the combined factor in the 4-factor model) demonstrated Acceptable to Excellent reliability.

```{r efa model fit indices}
fa.stats <- function(efa.model) {
  model_name <- deparse(substitute(efa.model))
  
  stats <- c(
    Chi_Square = round(efa.model$STATISTIC, 3),
    p_value = round(efa.model$PVAL, 3),
    TLI = round(efa.model$TLI, 3),
    RMSEA = round(efa.model$RMSEA[1], 3),
    RMSEA_CI_Lower = round(efa.model$RMSEA[2], 3),
    RMSEA_CI_Upper = round(efa.model$RMSEA[3], 3),
    BIC = round(efa.model$BIC, 3)
  )

  return(stats)
}
```

### 6.1  EFA models

#### EFA with 4 factors

```{r efa 4fas}
efa.4fas <- fa(poly_R, n.obs = nrow(dat), nfactors = 4, fm = "pa", rotate = "promax")
fa.stats(efa.4fas)
print(efa.4fas$loadings, cutoff = 0.3)
range(efa.4fas$communality)
efa.4fas$Phi
```

```{r plot efa 4fas results}
fa.diagram(efa.4fas, rsize = 1)
```

#### EFA with 5 factors

```{r efa 3 fas}
efa.5fas <- fa(poly_R, n.obs = nrow(dat), nfactors = 5, fm = "pa", rotate = "promax")
fa.stats(efa.5fas)
print(efa.5fas$loadings, cutoff = 0.3)
range(efa.5fas$communality)
efa.5fas$Phi
```

```{r plot efa 3fas results}
fa.diagram(efa.5fas, rsize = 1)
```

#### EFA with 1 factor

```{r efa 1 fa}
efa.1fa <- fa(poly_R, n.obs = nrow(dat), nfactors = 1, fm = "pa", rotate = "oblimin")
fa.stats(efa.1fa)
print(efa.1fa$loadings, cutoff = 0.3) 

range(efa.1fa$communality)
```

#### EFA model summary

```{r}
efa.model.list <- list(
  efa.5fas = fa.stats(efa.5fas),
  efa.4fas = fa.stats(efa.4fas),
  efa.1fa = fa.stats(efa.1fa))

efa.summary <- do.call(rbind, efa.model.list)
print(efa.summary)
```


### 6.2  Cronbach’s alpha for factor reliability

Factor internal consistency was evaluated using Cronbach’s alpha, one of the most common measures of internal consistency reliability (how well a set of items measures a single underlying construct).

```{r reliability Analysis}
factor.structure <- list(
  sr = soc_item22,
  hostility = soc_item22[, c("hos268", "hos267", "hos263", "hos262", "hos270")],
  emosup = soc_item22[, c("emo200", "emo203", "emo205", "emo222", "emo216")],
  friends = soc_item22[, c("fri230", "fri233", "fri237", "fri239", "fri247")],
  isolation = soc_item22[, c("lon260", "lon261", "lon253", "lon254", "rej276", "rej279", "rej281")],
  loneliness = soc_item22[, c("lon260", "lon261", "lon253", "lon254")],
  rejection = soc_item22[, c("rej276", "rej279", "rej281")]
)

get_alpha_summary <- function(df) {
  alpha.result <- psych::alpha(df)
  return(c(
    n_items = ncol(df),
    alpha = round(alpha.result$total$raw_alpha, 2)
  ))
}

alpha_summary <- t(sapply(factor.structure, get_alpha_summary))

alpha_summary <- as.data.frame(alpha_summary)
alpha_summary$Reliability <- cut(
  alpha_summary$alpha,
  breaks = c(-Inf, 0.7, 0.8, 0.9, Inf),
  labels = c("Poor", "Acceptable", "Good", "Excellent")
)

print(alpha_summary)
```

### 6.3 One-factor EFA results

We explored the factor structure of the social health variables using exploratory factor analysis (EFA). A four- or five-factor solution emerged, with moderately correlated factors, suggesting the presence of a potential general construct. 

To assess the extent to which a single general factor could account for the common variance among the items. We fit a unidimensional model with one factor (social relationship). In this model, all items demonstrated meaningful loadings on the single factor (all > 0.35), particularly those from the Rejection and Loneliness domains (most > 0.60). This general factor accounted for a substantial proportion of variance (> 30%) and exhibited strong internal consistency (Cronbach’s α > 0.8).

#### Loading of social relationship

```{r plot g loadings, warning=FALSE}
loadings <- as.data.frame(efa.1fa$loadings[])

loadings_df <- loadings %>%
  rownames_to_column("Item")

colnames(loadings_df)[2] <- "Loading"

ggplot(loadings_df, aes(x = reorder(Item, Loading), y = Loading, fill = Loading)) +
  geom_col(width = 0.6) +
  coord_flip() +
  scale_fill_gradient(low = "#FFE0B2", high = "#E65100") +
  theme_minimal(base_size = 12) +
  labs(title = "EFA loadings",
       x = "Item",
       y = "",
       fill = "Loading") +
  theme(
    axis.title = element_text(size = 14, family = "Arial"),
    axis.text = element_text(size = 12, color = "black", family = "Arial"),
    legend.text = element_text(size = 12, family = "Arial"),
    legend.title = element_text(size = 12, family = "Arial"),
    panel.grid = element_blank()
  )

ggsave(file.path(plot_dir, paste0("hcp", "_sr_factor_loadings.png")),
       width = 4, height = 5, dpi = 300)

```


### 6.4 Export EFA sr score

```{r get 1fa efa score}
efa.1fa.scores = factor.scores(soc_item22, efa.1fa, method = "regression")
efa.sr_score = efa.1fa.scores$scores

colnames(efa.sr_score) = "sr"

ggplot(data.frame(efa.sr_score), aes(x = efa.sr_score)) +
  geom_density(fill = "cadetblue3", alpha = 0.6, color = "darkslategray", linewidth = 0.5) +
  labs(
    title = "",
    x = "SR score",
    y = "Density"
  ) +
  theme_minimal() +
  theme(
    axis.title = element_text(size = 11, color = "black", family = "Arial"),
    axis.text  = element_text(size = 11, color = "black", family = "Arial"),
    legend.text  = element_text(size = 11, family = "Arial"),
    legend.title = element_text(size = 11, family = "Arial"),
    panel.grid.major = element_blank(),
    panel.background = element_rect(fill = "white", color = NA),
    plot.background  = element_rect(fill = "white", color = NA)
  )

ggsave(
  file.path(plot_dir, paste0("all", "_efa_sr_density.png")),
  width = 3, height = 2.5, dpi = 300
)
```

```{r combine efa g scores, warning=FALSE}
cerebel_cerebr_social_sr = bind_cols(dat, efa.sr_score)

output_file <- file.path(datadir, paste0("hcp_cerebel_cerebr_social_sr_n", nrow(dat), ".csv"))
write.csv(cerebel_cerebr_social_sr, output_file, row.names = FALSE)
```

----------

## 7  Confirmatory factor analysis (CFA)

CFAs were conducted to evaluate the factor structures identified in the EFA, using the `WLSMV` estimator. In the 5-factor model, the 22 items were specified to load onto 5 latent constructs consistent with the original scales: Emotional Support, Friendship, Loneliness, Perceived Rejection, and Perceived Hostility. 

```{r include=FALSE}
# ==== This text is for your reference only; it won't appear in the output ====
# In the 4-factor model, items from the Loneliness and Perceived Rejection scales were combined to form a single latent construct labeled Isolation, while the remaining items loaded onto 3 factors as in the 5-factor model.
```

- `estimator = "WLSMV"`: WLSMV stands for Weighted Least Squares Means and Variance adjusted estimator. It’s used in structural equation modeling (SEM) and CFA especially when dealing with ordinal data like Likert scales.

Example output: χ²/df = 3.05; RMSEA = 0.068, 90% CI [0.061, 0.075]; CFI = 0.983; TLI = 0.979; SRMR = .071, as well as satisfactory construct reliability and convergent validity for each factor, with composite reliability (CR) values ranging from 0.723 to 0.886, and average variance extracted (AVE) values ranged from 0.534 to 0.714. The 4-factor CFA model also exhibited satisfactory CRs (0.720-0.902) and AVEs (0.534-0.666), but its overall model performance was inferior compared to that of the 5-factor CFA model.

Overall, the five-factor CFA model demonstrated good fit to the data. The results provided adequate support for the proposed factor structure, with acceptable model fit indices and strong factor loadings, supporting the construct validity of the measurement model.

```{r cfa fit indices}
cfa.fit.stats <- function(model, round_digits = 3, print = TRUE) {

  stats <- lavaan::fitMeasures(model, c(
    "chisq", "df", "pvalue",
    "cfi", "tli", "rmsea", "rmsea.ci.lower", "rmsea.ci.upper", 
    "srmr"
  ))

  stats <- round(stats, round_digits)
  return(stats)
}
```

### 7.1  CFA models

#### Measure of factor reliability

- `r2`: indicate the proportion of variance in each observed indicator that is explained by its latent factor.
- `compRelSEM`: calculate composite Reliability (CR), which is a measure of internal consistency reliability for a latent construct, similar to Cronbach’s alpha. 
  - Values above 0.70 are generally considered acceptable for reliability.
- `AVE()`: Average Variance Extracted, which is a measure of convergent validity and tells how much variance in the observed variables (indicators) is explained by the latent construct (factor), on average.
  - AVE ≥ 0.50: Acceptable


#### CFA with 5 factors

```{R cfa 5fas, message = FALSE}
cfa.5fas.model <- '
  Loneliness =~ lon260 + lon261 + lon253 + lon254
  Hostility  =~ hos268 + hos267 + hos263 + hos262 + hos270
  EmoSupt    =~ emo200 + emo203 + emo205 + emo222 + emo216
  Friends    =~ fri230 + fri233 + fri237 + fri239 + fri247
  Rejection  =~ rej276 + rej279 + rej281
'

cfa.5fas <- cfa(cfa.5fas.model, data = soc_item22, estimator = "WLSMV", ordered = colnames(soc_item22))
cfa.fit.stats(cfa.5fas)

loadings = inspect(cfa.5fas, "std")$lambda
ifelse(abs(loadings) >= 0.1, round(loadings, 3), NA)
```

```{r cfa 5 fas R2}
inspect(cfa.5fas, "r2")
range(inspect(cfa.5fas, "r2"))
mean(inspect(cfa.5fas, "r2"))
```

```{r cfa 5fas reliability}
# factor reliability
compRelSEM(cfa.5fas)
AVE(cfa.5fas)
```

```{r cfa 5 fas plot loadings, warning=FALSE}
loadings_df = as.data.frame(loadings)
loadings_long <- loadings_df %>%
  rownames_to_column("Item") %>%
  pivot_longer(-Item, names_to = "Factor", values_to = "Loading") %>%
  # remove NA or zero loadings
  filter(!is.na(Loading) & Loading != 0) %>%
  arrange(Factor, Loading)

# Make Item a factor in the desired plotting order
loadings_long$Item <- factor(loadings_long$Item, levels = loadings_long$Item)

desired_order <- c("Rejection", "Loneliness", "Hostility", "Friends", "EmoSupt")
loadings_long$Factor <- factor(loadings_long$Factor, levels = desired_order)

my_colors <- c("olivedrab", "skyblue3", "khaki3","peachpuff3","tan3")

# Plot
ggplot(loadings_long, aes(x = Item, y = Loading, fill = Factor)) +
  geom_col(width = 0.6) +
  coord_flip() +
  scale_fill_manual(values = my_colors,
                    labels = c("Rejection", "Loneliness","Hostility", "Friendship", "Emotional support")) +
  theme_minimal(base_size = 12) +
  labs(title = "CFA loadings",
       x = "Item",
       y = "",
       fill = "Factors") +
  theme(
    axis.text.y = element_text(size = 9, family = "Arial"),
    legend.text = element_text(size = 9, family = "Arial"),
    legend.title = element_text(size = 10, family = "Arial"),
    panel.grid = element_blank()
  ) + 
  guides(fill = guide_legend(keywidth = 0.7, keyheight = 0.7))

ggsave(file.path(plot_dir, paste0("hcp_cfa_5factor_loadings.png")),
       width = 4, height = 5, dpi = 300)

```

```{r cfa 5fas factor cor}
inspect(cfa.5fas, "cor.lv")
```

#### CFA with 4 factors

```{R cfa 4fas, message = FALSE}
cfa.4fas.model <- '
  Isolation  =~ lon260 + lon261 + lon253 + lon254 + rej276 + rej279 + rej281
  Hostility  =~ hos268 + hos267 + hos263 + hos262 + hos270
  EmoSupt    =~ emo200 + emo203 + emo205 + emo222 + emo216
  Friends    =~ fri230 + fri233 + fri237 + fri239 + fri247
'

cfa.4fas <- cfa(cfa.4fas.model, data = soc_item22, estimator = "WLSMV", ordered = colnames(soc_item22))
cfa.fit.stats(cfa.4fas)
loadings = inspect(cfa.4fas, "std")$lambda
ifelse(abs(loadings) >= 0.1, round(loadings, 3), NA)
```

```{r cfa 4 fas R2}
inspect(cfa.4fas, "r2")
range(inspect(cfa.4fas, "r2"))
mean(inspect(cfa.4fas, "r2"))
```

```{r cfa 4fas reliability}
# factor reliability
compRelSEM(cfa.4fas)
AVE(cfa.4fas) # Average Variance Extracted
```

```{r cfa 4fas factor cor}
inspect(cfa.4fas, "cor.lv")
```

### 7.2 CFA model summary

```{r cfa summary}
cfa.model.list <- list(
  cfa.5fas = cfa.fit.stats(cfa.5fas),
  cfa.4fas = cfa.fit.stats(cfa.4fas))

cfa.summary <- do.call(rbind, cfa.model.list)
print(cfa.summary)
```

| Fit Index     | Description                                            | Acceptable Thresholds                                          |
|-------------------|----------------------------------------------------|----------------------------------------------------------------|
| χ² (Chi-square)   | Tests exact model fit; sensitive to sample size    | Non-significant preferred (p > .05); often ignored in large N  |
| χ²/df (Normed Chi-square) | Chi-square divided by degrees of freedom   | < 3 (good), < 5 (acceptable)                                   |
| CFI           | Comparative Fit Index; compares model to null model    | ≥ 0.95 (good), ≥ 0.90 (acceptable)                             |
| TLI           | Tucker-Lewis Index; penalizes for model complexity     | ≥ 0.95 (good), ≥ 0.90 (acceptable)                             |
| RMSEA         | Root Mean Square Error of Approximation                | ≤ 0.06 (good), ≤ 0.08 (acceptable); 90% CI should include 0.05 |
| SRMR          | Standardized Root Mean Square Residual                 | ≤ 0.08 (good), ≤ 0.10 (acceptable)                             |
| AVE           | Average Variance Extracted, measuring convergent validity  | ≥ 0.50 (acceptable), < 0.5 (problematic)                   |


### 7.3 Export CFA scores

```{r plot cfa 5 factors}
cfa.scores <- lavPredict(cfa.5fas)
cfa.scores = as.data.frame(cfa.scores)
scored_long <- cfa.scores %>%
  pivot_longer(cols = everything(), names_to = "Factor", values_to = "Score")

ggplot(scored_long, aes(x = Score)) +
  geom_histogram(bins = 30, fill = "skyblue", color = "black") +
  geom_vline(xintercept = 0, linetype = "dashed", color = "darkgray") +
  facet_wrap(~ Factor, scales = "free") +
  theme_minimal() +
  labs(title = "Distributions of CFA Scores - 5 factors", x = "Score", y = "Count")
```

```{r combine cfa scores, warning=FALSE}
cerebel_cerebr_social_facors = bind_cols(cerebel_cerebr_social_sr, cfa.scores)

output_file <- file.path(datadir, paste0("hcp_cerebel_cerebr_social_factors_n", nrow(dat), ".csv"))
write.csv(cerebel_cerebr_social_facors, output_file, row.names = FALSE)
```

----------

## Group difference of social relationship score

- no significance between the HCA and HCD groups.

```{r group difference, warning=FALSE}
group_data <- cerebel_cerebr_social_facors %>%
  mutate(subject = gsub("[0-9]", "", subject)) %>%   # keep letters only
  rename(group = subject)

group_data$group <- as.factor(group_data$group)

group_data %>%
  group_by(group) %>%
  summarise(
    mean = mean(sr, na.rm = TRUE),
    sd   = sd(sr, na.rm = TRUE)
  )
```


```{r t test for between cohorts}
var.test(sr ~ group, data = group_data)

t_results = t.test(sr ~ group, data = group_data)
t_results
```

```{r linear model for between cohorts}
mod_sr = lm(sr ~ group, data = group_data)
summary(mod_sr)

```

```{r hcpa and hcpd, warning=FALSE}
# write HCP-D data
hcpd_data <- group_data %>%
  filter(group == "HCD")

output_file <- file.path(datadir, develop_name, paste0(develop_name, "_brain_social_factors_n", nrow(hcpd_data), ".csv"))
write.csv(hcpd_data, output_file, row.names = FALSE)

# write HCP-A data
hcpa_data <- group_data %>%
  filter(group == "HCA")

output_file <- file.path(datadir, aging_name, paste0(aging_name, "_brain_social_factors_n", nrow(hcpa_data), ".csv"))
write.csv(hcpa_data, output_file, row.names = FALSE)
```

```{r mean and sd in hcpd}
hcpd_data %>%
  group_by(sex) %>%
  summarise(
    mean = mean(sr, na.rm = TRUE),
    sd   = sd(sr, na.rm = TRUE)
  )
```

```{r mean and sd in hcpa}
hcpa_data %>%
  group_by(sex) %>%
  summarise(
    mean = mean(sr, na.rm = TRUE),
    sd   = sd(sr, na.rm = TRUE)
  )
```

```{r equal variance between cohorts}
var.test(sr ~ sex, data = hcpd_data)
var.test(sr ~ sex, data = hcpa_data)
```

```{r}
t_sex_hcpd = t.test(sr ~ sex, var.equal = TRUE, data = hcpd_data)
t_sex_hcpd
```

```{r}
t_sex_hcpa = t.test(sr ~ sex, var.equal = TRUE, data = hcpa_data)
t_sex_hcpa
```

